{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f0ddac0-c5d0-4f96-af8a-5b871687cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U save_results\n",
    "#pip install -U db_queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410c0ea-851a-482e-b263-88cf138d090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES & FUNCTIONS -------------------------------------------------------\n",
    "# Import libraries\n",
    "import getpass\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pymysql\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Import Shared Functions\n",
    "from db_queries import get_demographics, get_ids, get_location_metadata, get_population, \\\n",
    "                       get_sequela_metadata, get_best_model_versions\n",
    "from save_results import save_results_epi, save_results_cod\n",
    "\n",
    "\n",
    "# Import SDI regression function \n",
    "# (this function runs a regression and returns the coefficient for association between SDI & incidence\n",
    "#  -- this coefficient can then be passed to the interpolation function to interpolate based on SDI)\n",
    "from sdi_regression import sdi_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a996123-0bd2-4e76-af86-d7f8c0c9a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DEFAULTS --------------------------------------------------------------------\n",
    "ind_split_default = {'intest': True, 'ints': False}\n",
    "sdi_interpolation_default = {'intest': True, 'ints': True}\n",
    "\n",
    "# USER-DEFINED RUN PARAMETERS --------------------------------------------------------\n",
    "# Set run parameters \n",
    "RELEASE = 16              # Numeric release id for the current GBD cycle\n",
    "LEVEL_3 = 'ints'          # Set to either 'ints' or 'intest'\n",
    "CLEAR_OUTPUT_DIR = False  # Do you want to clear out the contents of the output folder before launching (T/F)\n",
    "BEST = True               # Do you want to mark the resulting models as best during the upload (T/F)\n",
    "\n",
    "IND_SPLIT = ind_split_default[LEVEL_3]   # Do you want to split Indian subnational estimates based on CoD (T/F/default)\n",
    "SDI_INTERPOLATION = sdi_interpolation_default[LEVEL_3] # Do you want to interpolate estimates based on SDI (T/F/default)\n",
    "\n",
    "\n",
    "# DB CREDENTIALS ---------------------------------------------------------------------\n",
    "# Set the database host and name, and read in the username and password \n",
    "db_credentials = pd.read_csv('FILEPATH')\n",
    "EPI_DB_HOST = 'ADDRESS'\n",
    "EPI_DB_NAME = 'DATABASE'\n",
    "EPI_DB_USER = str(db_credentials.loc[0, 'user']) \n",
    "EPI_DB_PASS = str(db_credentials.loc[0, 'pw']) \n",
    "\n",
    "\n",
    "# USERNAME ---------------------------------------------------------------------------\n",
    "# Get the current username -- we'll use this below to submit jobs \n",
    "user = getpass.getuser()\n",
    "\n",
    "\n",
    "# I/O DIRECTORIES --------------------------------------------------------------------\n",
    "# Create input and output file paths based on cause and release\n",
    "input_dir = 'FILEPATH'\n",
    "output_dir = 'FILEPATH'\n",
    "\n",
    "\n",
    "# CAUSE, MODELABLE ENTITY, & SEQUELA IDS ---------------------------------------------\n",
    "# Indicate the meids for the core high-burden incidence models (used for the interpolate function)\n",
    "incidence_meids = {'intest': 10140, 'ints': 20291}\n",
    "\n",
    "# Indicate the meids for the low-burden incidence models (these include all data points and are used for citation tracking)\n",
    "bundle_meids = {'intest': 10139, 'ints': 20292}\n",
    "\n",
    "# Make dictionaries with cause ids, and ids for intermediate outputs \n",
    "cids = {'intest': [319, 320], 'ints': [959]}\n",
    "intermediate_ids_to_upload = {'intest': [2523], 'ints': [27540, 28000]}\n",
    "intermediate_ids_no_upload = {'intest': [23991, 23992], 'ints': [9999, 9959, 196800, 196801]}\n",
    "\n",
    "# Pull the list of all sequela ids that are needed for the current cause\n",
    "seq_meta = get_sequela_metadata(sequela_set_id=2, release_id=RELEASE)\n",
    "seq_ids = seq_meta.loc[seq_meta.cause_id.isin(cids[LEVEL_3]), 'modelable_entity_id'].tolist()\n",
    "\n",
    "# We want to upload outputs for cause ids, sequela ids, and select intermediate results that are useful for reference and collaborator requests\n",
    "upload_ids = cids[LEVEL_3] + seq_ids + intermediate_ids_to_upload[LEVEL_3]\n",
    "\n",
    "# The full set of ids that the pipeline produces estimates for include those that we upload, plus a few intermediate results that we don't upload\n",
    "output_ids = upload_ids + intermediate_ids_no_upload[LEVEL_3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96842eeb-0df2-4d17-a4db-5a6c0b464d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# IMPLIMENT THE EFFECTS OF SETTINGS --------------------------------------------------\n",
    "# If we're doing the CoD-based India subnational split then we need to pull the list of Indian sub-national IDs    \n",
    "if IND_SPLIT:\n",
    "    loc_meta = get_location_metadata(35, release_id = RELEASE)\n",
    "    ind_locs = loc_meta[loc_meta.path_to_top_parent.str.contains(',163,')]['location_id'].tolist()\n",
    "else:\n",
    "    ind_locs = []   \n",
    "    \n",
    "    \n",
    "# If we're going to interpolate based on SDI, run the sdi regression to get the coefficient    \n",
    "if SDI_INTERPOLATION:\n",
    "    best_model = get_best_model_versions(\"modelable_entity\", ids = [incidence_meids[LEVEL_3]], release_id = RELEASE)\n",
    "    best_model = best_model['model_version_id'].iloc[0]\n",
    "    sdi_coefs = sdi_regression(RELEASE, best_model, incidence_meids[LEVEL_3])\n",
    "    print(sdi_coefs)\n",
    "else:\n",
    "    sdi_coefs = None\n",
    "    \n",
    "\n",
    "# If we've requested the output directory be cleared, do so here, otherwise make sure all output directories exist    \n",
    "for output_id in output_ids + ['model_info']:\n",
    "    if CLEAR_OUTPUT_DIR:\n",
    "        shutil.rmtree(os.path.join(output_dir, str(output_id)), ignore_errors = True)\n",
    "    os.makedirs(os.path.join(output_dir, str(output_id)), exist_ok = True)\n",
    "\n",
    "    \n",
    "# SET LAUNCH PARAMETERS -----------------------------------------------------------\n",
    "# We're going to launch a job for every location, get the necessary locations now    \n",
    "cod_demog = get_demographics(gbd_team=\"cod\", release_id = RELEASE)\n",
    "locs = cod_demog['location_id']\n",
    "\n",
    "\n",
    "# We want to know the time that we launched the jobs so we can determine if all files in the output folder are newly created\n",
    "# (If we haven't cleared out the folder contents, then we need to know that all outputs were created by this launch and \n",
    "#  are not old residual files from a previous run)\n",
    "launch_time = datetime.now()\n",
    "RERUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eee360-aed8-423f-ba0c-0ac36c4edb1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# LAUNCH THE JOBS --------------------------------------------------------------------\n",
    "# Set for a rerun of failed jobs or a standard full run\n",
    "if (RERUN):\n",
    "    launch_locs = rerun_locs\n",
    "else:\n",
    "    launch_locs = locs\n",
    "\n",
    "\n",
    "# Loop through the locations and launch the jobs\n",
    "for loc in launch_locs:\n",
    "    # The jobs for Indian subnations (where we're doing the IND SPLIT) require more memory\n",
    "    if LEVEL_3 == 'intest' and loc in ind_locs:\n",
    "        mem = '100G'\n",
    "    else:\n",
    "        mem = '20G'\n",
    "\n",
    "    # Construct the sbatch command to submit the job    \n",
    "    submission_list = ['sbatch', '-J', f'{LEVEL_3}_{loc}', '-e', f'FILEPATH',\n",
    "                       '-o', f'FILEPATH', '-A', 'proj_erf',\n",
    "                       f'--mem={mem}', '-c', '4', '-t', '600', '-p', 'all.q', \n",
    "                       'FILEPATH' +  'FILEPATH/enteric_split.py ' + \n",
    "                       str(loc) + ' ' + str(RELEASE) + ' ' + str(LEVEL_3) + ' ' +\n",
    "                       str(sdi_coefs) + ' ' + str(IND_SPLIT)]\n",
    "    \n",
    "    submission_str = \" \".join(submission_list)\n",
    "    \n",
    "    # Submit the job\n",
    "    os.system(submission_str)\n",
    "\n",
    "\n",
    "# CHECK JOB STATUS -------------------------------------------------------------------    \n",
    "while True:\n",
    "    time.sleep(30)\n",
    "    \n",
    "    all_jobs = subprocess.check_output('squeue --me -o \"%j\"', shell = True)\n",
    "    all_jobs = all_jobs.decode().split(\"\\n\")[1:]\n",
    "\n",
    "    matching_jobs = [job for job in all_jobs if re.match(f\"^{LEVEL_3}\", job)]\n",
    "    if len(matching_jobs) == 0:\n",
    "        print('All jobs done running. Checking output files.')\n",
    "        break\n",
    "    else:\n",
    "        print('Jobs still running.  Will check again in a minute.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313c343-9173-4287-9ee8-26bb72149e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK OUTPUTS ----------------------------------------------------------------------\n",
    "# Define the function to check outputs (determines if outputs exist and if they were newly created during this run)\n",
    "def file_checker(file, launch):\n",
    "    exists = os.path.isfile(file)\n",
    "    if exists: \n",
    "        mtime = datetime.fromtimestamp(os.path.getmtime(file))\n",
    "        if mtime > launch_time:\n",
    "            return 'new'\n",
    "        else:\n",
    "            return 'old'\n",
    "    else:\n",
    "        return 'missing'\n",
    "\n",
    "# Run file checker function on all combinations of output_id and location to determine if each file is new, old, or missing \n",
    "# (new means the file was newly created during the current run; old means the file was created during a previous run; missing = no file exists)\n",
    "checks = [[id, loc, file_checker(os.path.join(output_dir, str(id), f\"{loc}.csv\"), launch_time)] for id in output_ids for loc in locs]\n",
    "checks = pd.DataFrame(checks, columns = ['meid', 'location_id', 'status'])\n",
    "checks['complete'] = checks['status'] == 'new'\n",
    "\n",
    "# Determine which MEIDs have a complete set of new files and are therefore ready for upload\n",
    "ready = checks.groupby(['meid'])['complete'].mean().reset_index()\n",
    "\n",
    "meids_to_upload = ready.loc[ready.complete==1, 'meid']\n",
    "meids_to_upload = [x for x in meids_to_upload if x in upload_ids]\n",
    "\n",
    "# Print out a frequency table of file status by MEID so we can see where things stand\n",
    "print(checks.groupby('meid')['status'].value_counts())\n",
    "\n",
    "# Determine which upload IDs are not complete (if any)\n",
    "missing_upload_ids = set(upload_ids) - set(meids_to_upload)\n",
    "\n",
    "if len(missing_upload_ids) == 0:\n",
    "    print(\"Results are complete for all upload IDs\")\n",
    "else:\n",
    "    print(\"The following upload ids do not have complete results: \" + str(missing_upload_ids))\n",
    "    rerun_locs = checks.loc[(checks['status'].isin(['old', 'missing'])) & (checks['meid'].isin(upload_ids)), 'location_id'].unique().tolist()\n",
    "    RERUN = True\n",
    "    \n",
    "    print(rerun_locs)\n",
    "    print(RERUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd37ce-18d2-41b0-8850-ca59245a72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE MODEL DESCRIPTION -------------------------------------------------------\n",
    "# Every model uploaded to the database needs a description\n",
    "# we'll build that here based on inputs\n",
    "\n",
    "# Every job saves a model_info file with details about the component inputs -- read those in here\n",
    "model_info = (pl.scan_csv(os.path.join(output_dir, 'model_info', '*.csv')).collect(streaming = True)).unique()\n",
    "\n",
    "# Make a list of all model_version_ids by model type (e.g. DisMod, CODEm)\n",
    "label = []\n",
    "for tool, group in model_info.group_by('tool'):\n",
    "    label.append(str(tool[0]) + ' = ' + ', '.join([str(id) for id in group['model_version_id']]))\n",
    "\n",
    "# Join everything together into a string label that we can use for the uploader and print for visual inspection during run    \n",
    "label = '; and '.join(label)\n",
    "description = f'Natural hx / CODEm hybrid using {label}, with python pipeline'\n",
    "print(description)\n",
    "\n",
    "\n",
    "# GET BUNDLE AND CROSSWALK VERSIONS FOR SOURCE TRACKING ------------------------------\n",
    "# We neeed to know the bundle_ids and crosswalk_version_ids for the input data used in the DisMod models for the uploader\n",
    "# as this is needed for source tracking.  We're going to pull that information from the database here\n",
    "\n",
    "# First, pull the list of the DisMod model version ids from the model_info table (compiled above)\n",
    "dismod_model_ids = model_info.filter(pl.col('tool') == 'dismod')['model_version_id'].to_list()\n",
    "dismod_model_ids = f\"({', '.join(str(id) for id in dismod_model_ids)})\"\n",
    "\n",
    "# Define the list of the variables we want\n",
    "varlist = ['modelable_entity_id', 'bundle_id', 'crosswalk_version_id'] \n",
    "\n",
    "# Connect to the epi database, open the cursor, and execute the SQL query\n",
    "db = pymysql.connect(host = EPI_DB_HOST, user = EPI_DB_USER, password = EPI_DB_PASS, database = EPI_DB_NAME) \n",
    "\n",
    "with db:\n",
    "    with db.cursor() as cursor:\n",
    "        cursor.execute('SELECT ' + ', '.join(varlist) + ' FROM model_version WHERE model_version_id IN ' + dismod_model_ids)\n",
    "\n",
    "        # Fetch all rows of data, put them in a data frame and add column names\n",
    "        model_data = pd.DataFrame(cursor.fetchall(), columns = varlist)\n",
    "\n",
    "# Get the input data bundle ids and store in space seperated string        \n",
    "bundle_list = model_data.loc[model_data['modelable_entity_id'] == bundle_meids[LEVEL_3], 'bundle_id'].tolist()\n",
    "bundles = ' '.join(map(str, bundle_list))\n",
    "\n",
    "# Get the input data crosswalk versions and store in space seperated string        \n",
    "xwalk_list = model_data.loc[model_data['bundle_id'].isin(bundle_list), 'crosswalk_version_id'].tolist()\n",
    "xwalks  = ' '.join(map(str, xwalk_list))\n",
    "\n",
    "print(bundles)\n",
    "print(xwalks)\n",
    "print(model_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677d299-3eea-4c18-a814-86110e0f7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SUBMIT THE JOBS TO UPLOAD THE MODELS -----------------------------------------------\n",
    "# Loop through the MEIDs that are ready for upload and submit a job to upload the corresponding estimates\n",
    "\n",
    "for id in meids_to_upload:\n",
    "    # CoD models are larger and therefore need more memory to upload\n",
    "    if id in cids[LEVEL_3]:\n",
    "        type = 'cod'\n",
    "        mem = '200G'\n",
    "        measures = 1 # CoD results are always measure 1, so we can hard code this\n",
    "\n",
    "    else:\n",
    "        type = 'epi'\n",
    "        mem = '100G'\n",
    "\n",
    "        # Non-fatal estimates can include a variety of measures (e.g. incidence, prevalence), \n",
    "        # so read in a sample file to find the list of measures\n",
    "        m_test = pl.read_csv(os.path.join(output_dir, str(id), '161.csv'))\n",
    "        measures = ' '.join(map(str, m_test['measure_id'].unique()))\n",
    "\n",
    "        \n",
    "    # Construct the sbatch command to submit the job    \n",
    "    submission_list = ['sbatch', '-J', f'upload_{id}', '-e', f'FILEPATH',\n",
    "                       '-o', f'FILEPATH', '-A', 'proj_erf',\n",
    "                       f'--mem={mem}', '-c', '4', '-t', '1000', '-p', 'all.q', \n",
    "                       'FILPATH ' +  'FILEPATH/upload_results.py ' + \n",
    "                       f'--type {type} --id {id} --path {os.path.join(output_dir, str(id))} --description \"{description}\" ' +\n",
    "                       f'--measure {measures} --best {BEST} --release {RELEASE} --bundle {bundles} --xwalk {xwalks}']\n",
    "\n",
    "    # Submit the job (and print the submission command for visual inspection)\n",
    "    submission_str = \" \".join(submission_list)\n",
    "    print(submission_str)\n",
    "    os.system(submission_str)\n",
    "    \n",
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
